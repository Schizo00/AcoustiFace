{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mayavi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# import open3d as o3d\n",
    "# import numpy as np\n",
    "\n",
    "# def plot_ply_with_coordinates(ply_path):\n",
    "#     # Read PLY file using Open3D\n",
    "#     point_cloud = o3d.io.read_point_cloud(ply_path)\n",
    "    \n",
    "#     # Extract coordinates from the point cloud\n",
    "#     coordinates = np.asarray(point_cloud.points)\n",
    "\n",
    "#     # Create a 3D scatter plot\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     # Add the point cloud to the plot\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=coordinates[:, 0],\n",
    "#         y=coordinates[:, 1],\n",
    "#         z=coordinates[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=3,\n",
    "#             color='blue',\n",
    "#         ),\n",
    "#         text=[str(i) for i in range(len(coordinates))],  # Use text for annotations\n",
    "#         name='Point Cloud'\n",
    "#     ))\n",
    "\n",
    "#     # Set layout properties\n",
    "#     fig.update_layout(\n",
    "#         scene=dict(\n",
    "#             aspectmode='data',\n",
    "#             xaxis=dict(title='X'),\n",
    "#             yaxis=dict(title='Y'),\n",
    "#             zaxis=dict(title='Z'),\n",
    "#         ),\n",
    "#         title='PLY Visualization with Coordinates'\n",
    "#     )\n",
    "\n",
    "#     # Show the plot\n",
    "#     fig.show()\n",
    "\n",
    "# # Replace 'path/to/your/file.ply' with the actual path to your PLY file\n",
    "# ply_file_path = './Preprocessed/id00012/mesh.ply'\n",
    "# plot_ply_with_coordinates(ply_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_tf import VoxDataset\n",
    "#import torch\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VoxDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 02:21:29.404821: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-04-21 02:21:29.404851: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-04-21 02:21:29.404858: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-04-21 02:21:29.405099: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-21 02:21:29.405448: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.32426515, -0.05228692, -0.2551459 , ..., -0.16584978,\n",
       "        0.10881446,  0.04802914], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh = dataset[0][1].numpy()\n",
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_0 = 0\n",
    "# min_0 = 0\n",
    "# max_1 = 0\n",
    "# min_1 = 0\n",
    "# max_2 = 0\n",
    "# min_2 = 0\n",
    "\n",
    "# for i in tqdm(mesh):\n",
    "#     if i[0] > max_0:\n",
    "#         max_0 = i[0]\n",
    "#     if i[1] > max_1:\n",
    "#         max_1 = i[1]\n",
    "#     if i[2] > max_2:\n",
    "#         max_2 = i[2]\n",
    "\n",
    "#     if i[0] < min_0:\n",
    "#         min_0 = i[0]\n",
    "#     if i[1] < min_1:\n",
    "#         min_1 = i[1]\n",
    "#     if i[2] < min_2:\n",
    "#         min_2 = i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_0 = max_0 - min_0\n",
    "# range_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_1 = max_1 - min_1\n",
    "# range_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_2 = max_2 - min_2\n",
    "# range_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# Load the point cloud from a file (replace with your file format and path)\n",
    "pcd = o3d.io.read_point_cloud(\"./Preprocessed/id00012/mesh.ply\")  # Adjust for file format (e.g., las, xyz)\n",
    "\n",
    "pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=float64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pcd.normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paint the 1500th point red.\n"
     ]
    }
   ],
   "source": [
    "print(\"Paint the 1500th point red.\")\n",
    "pcd.colors[3526] = [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find its 200 nearest neighbors, and paint them blue.\n"
     ]
    }
   ],
   "source": [
    "print(\"Find its 200 nearest neighbors, and paint them blue.\")\n",
    "# nose\n",
    "[k, idx_1, _] = pcd_tree.search_knn_vector_3d(pcd.points[3526], 3500)\n",
    "\n",
    "# trained on 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chin\n",
    "[k, idx_2, _] = pcd_tree.search_knn_vector_3d(pcd.points[3655], 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k, idx_3, _] = pcd_tree.search_knn_vector_3d(pcd.points[4051], 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k, idx_4, _] = pcd_tree.search_knn_vector_3d(pcd.points[4597], 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neck\n",
    "[k, idx_5, _] = pcd_tree.search_knn_vector_3d(pcd.points[3285], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chin\n",
    "[k, idx_6, _] = pcd_tree.search_knn_vector_3d(pcd.points[3404], 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array(idx_1).tolist() + np.array(idx_2).tolist() \n",
    "# + np.array(idx_3).tolist() + np.array(idx_4).tolist() + np.array(idx_5).tolist() + np.array(idx_6).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(set(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3540"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"weight_indices.npy\", np.array(idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(pcd.colors)[idx[1:], :] = [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find its neighbors with distance less than 0.2, and paint them green.\n"
     ]
    }
   ],
   "source": [
    "print(\"Find its neighbors with distance less than 0.2, and paint them green.\")\n",
    "[k, idx, _] = pcd_tree.search_radius_vector_3d(pcd.points[3526], 0.2)\n",
    "np.asarray(pcd.colors)[idx[1:], :] = [0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualize the point cloud.\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "print(\"Visualize the point cloud.\")\n",
    "o3d.visualization.draw_geometries([pcd],\n",
    "                                  zoom=0.5599,\n",
    "                                  front=[-0.4958, 0.8229, 0.2773],\n",
    "                                  lookat=[2.1126, 1.0163, -1.8543],\n",
    "                                  up=[0.1007, -0.2626, 0.9596], point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a NumPy matrix (or array) with dimensions (5023, 3) filled with zeros\n",
    "zeros_matrix = np.ones((5023, 3))\n",
    "\n",
    "# Print the matrix (optional)\n",
    "print(zeros_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ids:\n",
    "    zeros_matrix[i] = zeros_matrix[i] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [10., 10., 10.],\n",
       "       [10., 10., 10.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>audio_dir</th>\n",
       "      <th>emb_dir</th>\n",
       "      <th>mesh_dir</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00002.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00002.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00032.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00032.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00034.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00034.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00035.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00035.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00037.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00037.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0       id                         audio_dir  \\\n",
       "0             0           0  id00012  ./Preprocessed/id00012/00002.mp3   \n",
       "1             1           1  id00012  ./Preprocessed/id00012/00032.mp3   \n",
       "2             2           2  id00012  ./Preprocessed/id00012/00034.mp3   \n",
       "3             3           3  id00012  ./Preprocessed/id00012/00035.mp3   \n",
       "4             4           4  id00012  ./Preprocessed/id00012/00037.mp3   \n",
       "\n",
       "                                           emb_dir  \\\n",
       "0  ./Preprocessed/id00012/Embeddings/00002.mp3.npy   \n",
       "1  ./Preprocessed/id00012/Embeddings/00032.mp3.npy   \n",
       "2  ./Preprocessed/id00012/Embeddings/00034.mp3.npy   \n",
       "3  ./Preprocessed/id00012/Embeddings/00035.mp3.npy   \n",
       "4  ./Preprocessed/id00012/Embeddings/00037.mp3.npy   \n",
       "\n",
       "                          mesh_dir gender  \n",
       "0  ./Preprocessed/id00012/mesh.ply      m  \n",
       "1  ./Preprocessed/id00012/mesh.ply      m  \n",
       "2  ./Preprocessed/id00012/mesh.ply      m  \n",
       "3  ./Preprocessed/id00012/mesh.ply      m  \n",
       "4  ./Preprocessed/id00012/mesh.ply      m  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in value_counts.tolist() if x != 20 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id00012    20\n",
       "id05969    20\n",
       "id05983    20\n",
       "id05982    20\n",
       "id05981    20\n",
       "           ..\n",
       "id02936    20\n",
       "id02935    20\n",
       "id02928    20\n",
       "id02926    20\n",
       "id08892    20\n",
       "Name: count, Length: 5520, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[df['id'].isin(value_counts[value_counts >= 20].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id00012    20\n",
       "id05969    20\n",
       "id05983    20\n",
       "id05982    20\n",
       "id05981    20\n",
       "           ..\n",
       "id02936    20\n",
       "id02935    20\n",
       "id02928    20\n",
       "id02926    20\n",
       "id08892    20\n",
       "Name: count, Length: 5520, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>audio_dir</th>\n",
       "      <th>emb_dir</th>\n",
       "      <th>mesh_dir</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00002.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00002.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00032.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00032.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00034.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00034.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00035.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00035.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00037.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00037.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                         audio_dir  \\\n",
       "0           0  id00012  ./Preprocessed/id00012/00002.mp3   \n",
       "1           1  id00012  ./Preprocessed/id00012/00032.mp3   \n",
       "2           2  id00012  ./Preprocessed/id00012/00034.mp3   \n",
       "3           3  id00012  ./Preprocessed/id00012/00035.mp3   \n",
       "4           4  id00012  ./Preprocessed/id00012/00037.mp3   \n",
       "\n",
       "                                           emb_dir  \\\n",
       "0  ./Preprocessed/id00012/Embeddings/00002.mp3.npy   \n",
       "1  ./Preprocessed/id00012/Embeddings/00032.mp3.npy   \n",
       "2  ./Preprocessed/id00012/Embeddings/00034.mp3.npy   \n",
       "3  ./Preprocessed/id00012/Embeddings/00035.mp3.npy   \n",
       "4  ./Preprocessed/id00012/Embeddings/00037.mp3.npy   \n",
       "\n",
       "                          mesh_dir gender  \n",
       "0  ./Preprocessed/id00012/mesh.ply      m  \n",
       "1  ./Preprocessed/id00012/mesh.ply      m  \n",
       "2  ./Preprocessed/id00012/mesh.ply      m  \n",
       "3  ./Preprocessed/id00012/mesh.ply      m  \n",
       "4  ./Preprocessed/id00012/mesh.ply      m  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>audio_dir</th>\n",
       "      <th>emb_dir</th>\n",
       "      <th>mesh_dir</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00002.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00002.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00032.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00032.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00034.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00034.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00035.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00035.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00037.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00037.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0       id                         audio_dir  \\\n",
       "0             0           0  id00012  ./Preprocessed/id00012/00002.mp3   \n",
       "1             1           1  id00012  ./Preprocessed/id00012/00032.mp3   \n",
       "2             2           2  id00012  ./Preprocessed/id00012/00034.mp3   \n",
       "3             3           3  id00012  ./Preprocessed/id00012/00035.mp3   \n",
       "4             4           4  id00012  ./Preprocessed/id00012/00037.mp3   \n",
       "\n",
       "                                           emb_dir  \\\n",
       "0  ./Preprocessed/id00012/Embeddings/00002.mp3.npy   \n",
       "1  ./Preprocessed/id00012/Embeddings/00032.mp3.npy   \n",
       "2  ./Preprocessed/id00012/Embeddings/00034.mp3.npy   \n",
       "3  ./Preprocessed/id00012/Embeddings/00035.mp3.npy   \n",
       "4  ./Preprocessed/id00012/Embeddings/00037.mp3.npy   \n",
       "\n",
       "                          mesh_dir gender  \n",
       "0  ./Preprocessed/id00012/mesh.ply      m  \n",
       "1  ./Preprocessed/id00012/mesh.ply      m  \n",
       "2  ./Preprocessed/id00012/mesh.ply      m  \n",
       "3  ./Preprocessed/id00012/mesh.ply      m  \n",
       "4  ./Preprocessed/id00012/mesh.ply      m  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110400, 7)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"vox2_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>VGGFace2 ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id00012</td>\n",
       "      <td>n000012</td>\n",
       "      <td>m</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id00015</td>\n",
       "      <td>n000015</td>\n",
       "      <td>m</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00016</td>\n",
       "      <td>n000016</td>\n",
       "      <td>m</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id00017</td>\n",
       "      <td>n000017</td>\n",
       "      <td>m</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id00018</td>\n",
       "      <td>n000018</td>\n",
       "      <td>m</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id VGGFace2 ID  Gender    Set \n",
       "0  id00012      n000012       m    dev \n",
       "1  id00015      n000015       m    dev \n",
       "2  id00016      n000016       m    dev \n",
       "3  id00017      n000017       m   test \n",
       "4  id00018      n000018       m    dev "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['id'] = df2['id'].apply(lambda x : x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id00012'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(id):\n",
    "    if id in df2['id'].tolist():\n",
    "        return df2.loc[df2['id'] == id, 'Gender '].iloc[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n"
     ]
    }
   ],
   "source": [
    "print(get_gender(\"id08887\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['gender'] = df1['id'].apply(get_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107300, 8)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>audio_dir</th>\n",
       "      <th>emb_dir</th>\n",
       "      <th>mesh_dir</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00002.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00002.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00032.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00032.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00034.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00034.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00035.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00035.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>id00012</td>\n",
       "      <td>./Preprocessed/id00012/00037.mp3</td>\n",
       "      <td>./Preprocessed/id00012/Embeddings/00037.mp3.npy</td>\n",
       "      <td>./Preprocessed/id00012/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107295</th>\n",
       "      <td>107295</td>\n",
       "      <td>107576</td>\n",
       "      <td>107635</td>\n",
       "      <td>id08892</td>\n",
       "      <td>./Preprocessed/id08892/00053.mp3</td>\n",
       "      <td>./Preprocessed/id08892/Embeddings/00053.mp3.npy</td>\n",
       "      <td>./Preprocessed/id08892/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107296</th>\n",
       "      <td>107296</td>\n",
       "      <td>107577</td>\n",
       "      <td>107636</td>\n",
       "      <td>id08892</td>\n",
       "      <td>./Preprocessed/id08892/00054.mp3</td>\n",
       "      <td>./Preprocessed/id08892/Embeddings/00054.mp3.npy</td>\n",
       "      <td>./Preprocessed/id08892/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107297</th>\n",
       "      <td>107297</td>\n",
       "      <td>107578</td>\n",
       "      <td>107637</td>\n",
       "      <td>id08892</td>\n",
       "      <td>./Preprocessed/id08892/00055.mp3</td>\n",
       "      <td>./Preprocessed/id08892/Embeddings/00055.mp3.npy</td>\n",
       "      <td>./Preprocessed/id08892/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107298</th>\n",
       "      <td>107298</td>\n",
       "      <td>107579</td>\n",
       "      <td>107638</td>\n",
       "      <td>id08892</td>\n",
       "      <td>./Preprocessed/id08892/00057.mp3</td>\n",
       "      <td>./Preprocessed/id08892/Embeddings/00057.mp3.npy</td>\n",
       "      <td>./Preprocessed/id08892/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107299</th>\n",
       "      <td>107299</td>\n",
       "      <td>107580</td>\n",
       "      <td>107639</td>\n",
       "      <td>id08892</td>\n",
       "      <td>./Preprocessed/id08892/00058.mp3</td>\n",
       "      <td>./Preprocessed/id08892/Embeddings/00058.mp3.npy</td>\n",
       "      <td>./Preprocessed/id08892/mesh.ply</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0       id  \\\n",
       "0                  0             0           0  id00012   \n",
       "1                  1             1           1  id00012   \n",
       "2                  2             2           2  id00012   \n",
       "3                  3             3           3  id00012   \n",
       "4                  4             4           4  id00012   \n",
       "...              ...           ...         ...      ...   \n",
       "107295        107295        107576      107635  id08892   \n",
       "107296        107296        107577      107636  id08892   \n",
       "107297        107297        107578      107637  id08892   \n",
       "107298        107298        107579      107638  id08892   \n",
       "107299        107299        107580      107639  id08892   \n",
       "\n",
       "                               audio_dir  \\\n",
       "0       ./Preprocessed/id00012/00002.mp3   \n",
       "1       ./Preprocessed/id00012/00032.mp3   \n",
       "2       ./Preprocessed/id00012/00034.mp3   \n",
       "3       ./Preprocessed/id00012/00035.mp3   \n",
       "4       ./Preprocessed/id00012/00037.mp3   \n",
       "...                                  ...   \n",
       "107295  ./Preprocessed/id08892/00053.mp3   \n",
       "107296  ./Preprocessed/id08892/00054.mp3   \n",
       "107297  ./Preprocessed/id08892/00055.mp3   \n",
       "107298  ./Preprocessed/id08892/00057.mp3   \n",
       "107299  ./Preprocessed/id08892/00058.mp3   \n",
       "\n",
       "                                                emb_dir  \\\n",
       "0       ./Preprocessed/id00012/Embeddings/00002.mp3.npy   \n",
       "1       ./Preprocessed/id00012/Embeddings/00032.mp3.npy   \n",
       "2       ./Preprocessed/id00012/Embeddings/00034.mp3.npy   \n",
       "3       ./Preprocessed/id00012/Embeddings/00035.mp3.npy   \n",
       "4       ./Preprocessed/id00012/Embeddings/00037.mp3.npy   \n",
       "...                                                 ...   \n",
       "107295  ./Preprocessed/id08892/Embeddings/00053.mp3.npy   \n",
       "107296  ./Preprocessed/id08892/Embeddings/00054.mp3.npy   \n",
       "107297  ./Preprocessed/id08892/Embeddings/00055.mp3.npy   \n",
       "107298  ./Preprocessed/id08892/Embeddings/00057.mp3.npy   \n",
       "107299  ./Preprocessed/id08892/Embeddings/00058.mp3.npy   \n",
       "\n",
       "                               mesh_dir gender  \n",
       "0       ./Preprocessed/id00012/mesh.ply      m  \n",
       "1       ./Preprocessed/id00012/mesh.ply      m  \n",
       "2       ./Preprocessed/id00012/mesh.ply      m  \n",
       "3       ./Preprocessed/id00012/mesh.ply      m  \n",
       "4       ./Preprocessed/id00012/mesh.ply      m  \n",
       "...                                 ...    ...  \n",
       "107295  ./Preprocessed/id08892/mesh.ply      m  \n",
       "107296  ./Preprocessed/id08892/mesh.ply      m  \n",
       "107297  ./Preprocessed/id08892/mesh.ply      m  \n",
       "107298  ./Preprocessed/id08892/mesh.ply      m  \n",
       "107299  ./Preprocessed/id08892/mesh.ply      m  \n",
       "\n",
       "[65240 rows x 8 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['gender'] == \"m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones((5023,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, i in enumerate(ones):\n",
    "    for index2, j in enumerate(i):\n",
    "        ones[index1][index2] = (index1 * 3) + index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 1.0000e+00, 2.0000e+00],\n",
       "       [3.0000e+00, 4.0000e+00, 5.0000e+00],\n",
       "       [6.0000e+00, 7.0000e+00, 8.0000e+00],\n",
       "       ...,\n",
       "       [1.5060e+04, 1.5061e+04, 1.5062e+04],\n",
       "       [1.5063e+04, 1.5064e+04, 1.5065e+04],\n",
       "       [1.5066e+04, 1.5067e+04, 1.5068e+04]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10548., 10549., 10550.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones[3516]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "zeros = np.zeros([1,15069])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import tensorflow as tf\n",
    "from dataset_tf import VoxDataset, DataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load the point cloud from a file (replace with your file format and path)\n",
    "pcd = np.array(o3d.io.read_point_cloud(\"./Preprocessed/id00012/mesh.ply\").points)  # Adjust for file format (e.g., las, xyz)\n",
    "pcd1 = np.array(o3d.io.read_point_cloud(\"./Preprocessed/id00015/mesh.ply\").points)  # Adjust for file format (e.g., las, xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5023, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd = tf.expand_dims(pcd, axis=0)\n",
    "pcd1 = tf.expand_dims(pcd1, axis=0)\n",
    "pcd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directed_hausdorff(point_cloud_A, point_cloud_B):\n",
    "  '''\n",
    "  input:\n",
    "    point_cloud_A: Tensor, B x N x 3\n",
    "    point_cloud_B: Tensor, B x N x 3\n",
    "  return:\n",
    "    Tensor, B, directed hausdorff distance, A -> B\n",
    "  '''\n",
    "  npoint = point_cloud_A.shape[1]\n",
    "\n",
    "  A = tf.expand_dims(point_cloud_A, axis=2) # (B, N, 1, 3)\n",
    "  A = tf.tile(A, (1, 1, npoint, 1)) # (B, N, N, 3)\n",
    "\n",
    "  B = tf.expand_dims(point_cloud_B, axis=1) # (B, 1, N, 3)\n",
    "  B = tf.tile(B, (1, npoint, 1, 1)) # (B, N, N, 3)\n",
    "\n",
    "  distances = tf.math.squared_difference(B, A) # (B, N, N, 3)\n",
    "  # print(distances.shape)\n",
    "  # print(distances)\n",
    "  distances = tf.reduce_sum(distances, axis=-1) # (B, N, N, 1)\n",
    "  distances = tf.sqrt(distances) # (B, N, N)\n",
    "\n",
    "  shortest_dists, _ = tf.nn.top_k(-distances)\n",
    "  shortest_dists = tf.squeeze(-shortest_dists) # (B, N)\n",
    "\n",
    "  hausdorff_dists, _ = tf.nn.top_k(shortest_dists) # (B, 1)\n",
    "  hausdorff_dists = tf.squeeze(hausdorff_dists)\n",
    "\n",
    "  return hausdorff_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VoxDataset()\n",
    "data = DataGenerator(dataset, batch_size=8)\n",
    "# batch1 = tf.reshape(data[0][1], [1,5023,3]) \n",
    "# batch2 = tf.reshape(data[10][1], [1,5023,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.144366, shape=(), dtype=float32)\n",
      "tf.Tensor(8.288732, shape=(), dtype=float32)\n",
      "tf.Tensor(8.288732, shape=(), dtype=float32)\n",
      "tf.Tensor(7.8563304, shape=(), dtype=float32)\n",
      "tf.Tensor(7.8563304, shape=(), dtype=float32)\n",
      "tf.Tensor(6.630393, shape=(), dtype=float32)\n",
      "tf.Tensor(5.404456, shape=(), dtype=float32)\n",
      "tf.Tensor(5.404456, shape=(), dtype=float32)\n",
      "tf.Tensor(8.67176, shape=(), dtype=float32)\n",
      "tf.Tensor(8.67176, shape=(), dtype=float32)\n",
      "tf.Tensor(9.3198805, shape=(), dtype=float32)\n",
      "tf.Tensor(9.968001, shape=(), dtype=float32)\n",
      "tf.Tensor(9.968001, shape=(), dtype=float32)\n",
      "tf.Tensor(5.9246564, shape=(), dtype=float32)\n",
      "tf.Tensor(5.9246564, shape=(), dtype=float32)\n",
      "tf.Tensor(10.754522, shape=(), dtype=float32)\n",
      "tf.Tensor(15.584388, shape=(), dtype=float32)\n",
      "tf.Tensor(15.584388, shape=(), dtype=float32)\n",
      "tf.Tensor(15.535564, shape=(), dtype=float32)\n",
      "tf.Tensor(15.535564, shape=(), dtype=float32)\n",
      "tf.Tensor(17.355995, shape=(), dtype=float32)\n",
      "tf.Tensor(19.176424, shape=(), dtype=float32)\n",
      "tf.Tensor(19.176424, shape=(), dtype=float32)\n",
      "tf.Tensor(10.473376, shape=(), dtype=float32)\n",
      "tf.Tensor(10.473376, shape=(), dtype=float32)\n",
      "tf.Tensor(15.086683, shape=(), dtype=float32)\n",
      "tf.Tensor(19.699991, shape=(), dtype=float32)\n",
      "tf.Tensor(19.699991, shape=(), dtype=float32)\n",
      "tf.Tensor(16.757368, shape=(), dtype=float32)\n",
      "tf.Tensor(16.757368, shape=(), dtype=float32)\n",
      "tf.Tensor(12.014215, shape=(), dtype=float32)\n",
      "tf.Tensor(7.271064, shape=(), dtype=float32)\n",
      "tf.Tensor(7.271064, shape=(), dtype=float32)\n",
      "tf.Tensor(9.491757, shape=(), dtype=float32)\n",
      "tf.Tensor(9.491757, shape=(), dtype=float32)\n",
      "tf.Tensor(8.490343, shape=(), dtype=float32)\n",
      "tf.Tensor(7.488929, shape=(), dtype=float32)\n",
      "tf.Tensor(7.488929, shape=(), dtype=float32)\n",
      "tf.Tensor(7.6318264, shape=(), dtype=float32)\n",
      "tf.Tensor(7.6318264, shape=(), dtype=float32)\n",
      "tf.Tensor(12.355185, shape=(), dtype=float32)\n",
      "tf.Tensor(17.078543, shape=(), dtype=float32)\n",
      "tf.Tensor(17.078543, shape=(), dtype=float32)\n",
      "tf.Tensor(10.344673, shape=(), dtype=float32)\n",
      "tf.Tensor(10.344673, shape=(), dtype=float32)\n",
      "tf.Tensor(12.441725, shape=(), dtype=float32)\n",
      "tf.Tensor(14.538776, shape=(), dtype=float32)\n",
      "tf.Tensor(14.538776, shape=(), dtype=float32)\n",
      "tf.Tensor(9.186956, shape=(), dtype=float32)\n",
      "tf.Tensor(9.186956, shape=(), dtype=float32)\n",
      "tf.Tensor(7.0457993, shape=(), dtype=float32)\n",
      "tf.Tensor(4.9046426, shape=(), dtype=float32)\n",
      "tf.Tensor(4.9046426, shape=(), dtype=float32)\n",
      "tf.Tensor(7.0890617, shape=(), dtype=float32)\n",
      "tf.Tensor(7.0890617, shape=(), dtype=float32)\n",
      "tf.Tensor(8.844244, shape=(), dtype=float32)\n",
      "tf.Tensor(10.599425, shape=(), dtype=float32)\n",
      "tf.Tensor(10.599425, shape=(), dtype=float32)\n",
      "tf.Tensor(8.960012, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m batch1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(data[i][\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5023\u001b[39m,\u001b[38;5;241m3\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m201.41335\u001b[39m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[0;32m----> 4\u001b[0m     batch2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5023\u001b[39m,\u001b[38;5;241m3\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m201.41335\u001b[39m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mreduce_mean(directed_hausdorff(batch1, batch2)\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "File \u001b[0;32m~/FYP/dataset_tf.py:78\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     76\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m     77\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[0;32m---> 78\u001b[0m inputs, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_idx, end_idx)])\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(inputs), np\u001b[38;5;241m.\u001b[39marray(outputs)\n",
      "File \u001b[0;32m~/FYP/dataset_tf.py:78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m     77\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[0;32m---> 78\u001b[0m inputs, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_idx, end_idx)])\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(inputs), np\u001b[38;5;241m.\u001b[39marray(outputs)\n",
      "File \u001b[0;32m~/FYP/dataset_tf.py:30\u001b[0m, in \u001b[0;36mVoxDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     29\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embedding(index)\n\u001b[0;32m---> 30\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast((embedding \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_max) , tf\u001b[38;5;241m.\u001b[39mfloat32), tf\u001b[38;5;241m.\u001b[39mcast((mesh \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmesh_max) , tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/FYP/dataset_tf.py:44\u001b[0m, in \u001b[0;36mVoxDataset._get_mesh\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_mesh\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     43\u001b[0m     mesh_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotations\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmesh_dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 44\u001b[0m     pcd \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_triangle_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     pcd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pcd\u001b[38;5;241m.\u001b[39mvertices)\n\u001b[1;32m     46\u001b[0m     pcd \u001b[38;5;241m=\u001b[39m pcd\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    batch1 = tf.reshape(data[i][1], [8,5023,3]) * 201.41335 \n",
    "    for j in range(len(data)):\n",
    "        batch2 = tf.reshape(data[j][1], [8,5023,3]) * 201.41335 \n",
    "        print(tf.reduce_mean(directed_hausdorff(batch1, batch2).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones([2,4,3])\n",
    "x[0][0] = [0,0,0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 3), dtype=float64, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_indices = tf.where(tf.reduce_sum(tf.abs(x), axis=-1) > 0)\n",
    "new = tf.gather_nd(x, non_zero_indices)\n",
    "# tf.squeeze(new, axis=-1)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nose_bridge,r_eye_lid,l_eye_lid,lip,r_lip_bend,l_lip_bend,r_lip_jaw,l_lip_jaw,lip_chin,orbital_lower,oribtal_upper,puffer,mouth_corner,jaw_end,ear_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_bridge =  tf.math.reduce_euclidean_norm(y_test[3516],y_test[3526]) - tf.math.reduce_euclidean_norm(y_pred[3516],y_pred[3526])\n",
    "r_eye_lid =  tf.math.reduce_euclidean_norm(y_test[3690], y_test[2265]) - tf.math.reduce_euclidean_norm(y_pred[3690], y_pred[2265])\n",
    "l_eye_lid =  tf.math.reduce_euclidean_norm(y_test[3856], y_test[809]) - tf.math.reduce_euclidean_norm(y_pred[3856], y_pred[809])\n",
    "lip =  tf.math.reduce_euclidean_norm(y_test[3543], y_test[3503]) - tf.math.reduce_euclidean_norm(y_pred[3543], y_pred[3503])\n",
    "r_lip_bend =  tf.math.reduce_euclidean_norm(y_test[2850], y_test[3798]) - tf.math.reduce_euclidean_norm(y_pred[2850], y_pred[3798])\n",
    "l_lip_bend =  tf.math.reduce_euclidean_norm(y_test[1735], y_test[3021]) - tf.math.reduce_euclidean_norm(y_pred[1735], y_pred[3021])\n",
    "r_lip_jaw = tf.math.reduce_euclidean_norm(y_test[3798], y_test[3406]) - tf.math.reduce_euclidean_norm(y_pred[3798], y_pred[3406])\n",
    "l_lip_jaw = tf.math.reduce_euclidean_norm(y_test[3021], y_test[3614]) - tf.math.reduce_euclidean_norm(y_pred[3021], y_pred[3614])\n",
    "lip_chin =  tf.math.reduce_euclidean_norm(y_test[3503], y_test[3487]) - tf.math.reduce_euclidean_norm(y_pred[3503], y_pred[3487])\n",
    "orbital_lower =  tf.math.reduce_euclidean_norm(y_test[3710], y_test[3866]) - tf.math.reduce_euclidean_norm(y_pred[3710], y_pred[3866])\n",
    "oribtal_upper = tf.math.reduce_euclidean_norm(y_test[3154], y_test[2135]) - tf.math.reduce_euclidean_norm(y_pred[3154], y_pred[2135])\n",
    "puffer = tf.math.reduce_euclidean_norm(y_test[3436], y_test[3667]) - tf.math.reduce_euclidean_norm(y_pred[3436], y_pred[3667])\n",
    "mouth_corner = tf.math.reduce_euclidean_norm(y_test[2827], y_test[1710]) - tf.math.reduce_euclidean_norm(y_pred[2827], y_pred[1710])\n",
    "jaw_end = tf.math.reduce_euclidean_norm(y_test[3406], y_test[3614]) - tf.math.reduce_euclidean_norm(y_pred[3406], y_pred[3614])\n",
    "ear_end = tf.math.reduce_euclidean_norm(y_test[856], y_test[288]) - tf.math.reduce_euclidean_norm(y_pred[856], y_pred[288])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_func = linear_interpolation(pcd)\n",
    "  # Example usage: point_on_line = line_func(0.5)  # Get point at t=0.5\n",
    "\n",
    "  # Cubic spline interpolation\n",
    "spline = cubic_spline_interpolation(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nose_bridge =  tf.norm(y_test[j,3516] - y_test[j,3526],ord='euclidean') - tf.norm(y_pred[j,3516] - y_pred[j,3526],ord='euclidean')\n",
    "            # r_eye_lid =  tf.norm(y_test[j,3690] - y_test[j,2265],ord='euclidean') - tf.norm(y_pred[j,3690] - y_pred[j,2265],ord='euclidean')\n",
    "            # l_eye_lid =  tf.norm(y_test[j,3856] - y_test[j,809],ord='euclidean') - tf.norm(y_pred[j,3856] - y_pred[j,809],ord='euclidean')\n",
    "            # lip =  tf.norm(y_test[j,3543] - y_test[j,3503],ord='euclidean') - tf.norm(y_pred[j,3543] - y_pred[j,3503],ord='euclidean')\n",
    "            # r_lip_bend =  tf.norm(y_test[j,2850] - y_test[j,3798],ord='euclidean') - tf.norm(y_pred[j,2850] - y_pred[j,3798],ord='euclidean')\n",
    "            # l_lip_bend =  tf.norm(y_test[j,1735] - y_test[j,3021],ord='euclidean') - tf.norm(y_pred[j,1735] - y_pred[j,3021],ord='euclidean')\n",
    "            # r_lip_jaw = tf.norm(y_test[j,3798] - y_test[j,3406],ord='euclidean') - tf.norm(y_pred[j,3798] - y_pred[j,3406],ord='euclidean')\n",
    "            # l_lip_jaw = tf.norm(y_test[j,3021] - y_test[j,3614],ord='euclidean') - tf.norm(y_pred[j,3021] - y_pred[j,3614],ord='euclidean')\n",
    "            # lip_chin =  tf.norm(y_test[j,3503] - y_test[j,3487],ord='euclidean') - tf.norm(y_pred[j,3503] - y_pred[j,3487],ord='euclidean')\n",
    "            # orbital_lower =  tf.norm(y_test[j,3710] - y_test[j,3866],ord='euclidean') - tf.norm(y_pred[j,3710] - y_pred[j,3866],ord='euclidean')\n",
    "            # oribtal_upper = tf.norm(y_test[j,3154] - y_test[j,2135],ord='euclidean') - tf.norm(y_pred[j,3154] - y_pred[j,2135],ord='euclidean')\n",
    "            # puffer = tf.norm(y_test[j,3436] - y_test[j,3667],ord='euclidean') - tf.norm(y_pred[j,3436] - y_pred[j,3667],ord='euclidean')\n",
    "            # mouth_corner = tf.norm(y_test[j,2827] - y_test[j,1710],ord='euclidean') - tf.norm(y_pred[j,2827] - y_pred[j,1710],ord='euclidean')\n",
    "            # jaw_end = tf.norm(y_test[j,3406] - y_test[j,3614],ord='euclidean') - tf.norm(y_pred[j,3406] - y_pred[j,3614],ord='euclidean')\n",
    "            # ear_end = tf.norm(y_test[j,856] - y_test[j,288],ord='euclidean') - tf.norm(y_pred[j,856] - y_pred[j,288],ord='euclidean')\n",
    "\n",
    "            # diff_tot = [nose_bridge,r_eye_lid,l_eye_lid,lip,r_lip_bend,l_lip_bend,r_lip_jaw,l_lip_jaw,lip_chin,orbital_lower,oribtal_upper,puffer,mouth_corner,jaw_end,ear_end]\n",
    "\n",
    "\n",
    "            # nose_bridge_l_loss = tf.norm(y_test[j,3516] - y_pred[j,3516],ord='euclidean')\n",
    "            # r_eye_lid_l_loss = tf.norm(y_test[j,3690] - y_pred[j,3690],ord='euclidean')\n",
    "            # l_eye_lid_l_loss = tf.norm(y_test[j,3856] - y_pred[j,3856],ord='euclidean')\n",
    "            # lip_l_loss = tf.norm(y_test[j,3543] - y_pred[j,3543],ord='euclidean')\n",
    "            # r_lip_bend_l_loss = tf.norm(y_test[j,2850] - y_pred[j,2850],ord='euclidean')\n",
    "            # l_lip_bend_l_loss = tf.norm(y_test[j,1735] - y_pred[j,1735],ord='euclidean')\n",
    "            # r_lip_jaw_l_loss = tf.norm(y_test[j,3798] - y_pred[j,3798],ord='euclidean')\n",
    "            # l_lip_jaw_l_loss = tf.norm(y_test[j,3021] - y_pred[j,3021],ord='euclidean')\n",
    "            # lip_chin_l_loss = tf.norm(y_test[j,3503] - y_pred[j,3503],ord='euclidean')\n",
    "            # orbital_lower_l_loss = tf.norm(y_test[j,3710] - y_pred[j,3710],ord='euclidean')\n",
    "            # oribtal_upper_l_loss = tf.norm(y_test[j,3154] - y_pred[j,3154],ord='euclidean')\n",
    "            # puffer_l_loss = tf.norm(y_test[j,3436] - y_pred[j,3436],ord='euclidean')\n",
    "            # mouth_corner_l_loss = tf.norm(y_test[j,2827] - y_pred[j,2827],ord='euclidean')\n",
    "            # jaw_end_l_loss = tf.norm(y_test[j,3406] - y_pred[j,3406],ord='euclidean')\n",
    "            # ear_end_l_loss = tf.norm(y_test[j,856] - y_pred[j,856],ord='euclidean')\n",
    "\n",
    "\n",
    "            # nose_bridge_r_loss = tf.norm(y_test[j,3526] - y_pred[j,3526],ord='euclidean')\n",
    "            # r_eye_lid_r_loss = tf.norm(y_test[j,2265] - y_pred[j,2265],ord='euclidean')\n",
    "            # l_eye_lid_r_loss = tf.norm(y_test[j,809] - y_pred[j,809],ord='euclidean')\n",
    "            # lip_r_loss = tf.norm(y_test[j,3503] - y_pred[j,3503],ord='euclidean')\n",
    "            # r_lip_bend_r_loss = tf.norm(y_test[j,3798] - y_pred[j,3798],ord='euclidean')\n",
    "            # l_lip_bend_r_loss = tf.norm(y_test[j,3021] - y_pred[j,3021],ord='euclidean')\n",
    "            # r_lip_jaw_r_loss = tf.norm(y_test[j,3406] - y_pred[j,3406],ord='euclidean')\n",
    "            # l_lip_jaw_r_loss = tf.norm(y_test[j,3614] - y_pred[j,3614],ord='euclidean')\n",
    "            # lip_chin_r_loss = tf.norm(y_test[j,3487] - y_pred[j,3487],ord='euclidean')\n",
    "            # orbital_lower_r_loss = tf.norm(y_test[j,3866] - y_pred[j,3866],ord='euclidean')\n",
    "            # oribtal_upper_r_loss = tf.norm(y_test[j,2135] - y_pred[j,2135],ord='euclidean')\n",
    "            # puffer_r_loss = tf.norm(y_test[j,3667] - y_pred[j,3667],ord='euclidean')\n",
    "            # mouth_corner_r_loss = tf.norm(y_test[j,1710] - y_pred[j,1710],ord='euclidean')\n",
    "            # jaw_end_r_loss = tf.norm(y_test[j,3614] - y_pred[j,3614],ord='euclidean')\n",
    "            # ear_end_r_loss = tf.norm(y_test[j,288] - y_pred[j,288],ord='euclidean')\n",
    "\n",
    "            # nose_bridge_loss = tf.norm(nose_bridge_l_loss - nose_bridge_r_loss, ord='euclidean') ** 2\n",
    "            # r_eye_lid_loss = tf.norm(r_eye_lid_l_loss - r_eye_lid_r_loss , ord='euclidean') ** 2\n",
    "            # l_eye_lid_loss = tf.norm(l_eye_lid_l_loss - l_eye_lid_r_loss, ord='euclidean') ** 2\n",
    "            # lip_loss = tf.norm(lip_l_loss - lip_r_loss, ord='euclidean') ** 2\n",
    "            # r_lip_bend_loss = tf.norm(r_lip_bend_l_loss - r_lip_bend_r_loss , ord='euclidean') ** 2\n",
    "            # l_lip_bend_loss = tf.norm(l_lip_bend_l_loss - l_eye_lid_r_loss , ord='euclidean') ** 2\n",
    "            # r_lip_jaw_loss = tf.norm(r_lip_jaw_l_loss - r_lip_jaw_r_loss , ord='euclidean') ** 2\n",
    "            # l_lip_jaw_loss = tf.norm(l_lip_jaw_l_loss - l_lip_jaw_r_loss, ord='euclidean') ** 2\n",
    "            # lip_chin_loss = tf.norm(lip_chin_l_loss - lip_chin_r_loss, ord='euclidean') ** 2\n",
    "            # orbital_lower_loss = tf.norm(orbital_lower_l_loss - orbital_lower_r_loss , ord='euclidean') ** 2\n",
    "            # oribtal_upper_loss = tf.norm(oribtal_upper_l_loss - oribtal_upper_r_loss, ord='euclidean') ** 2\n",
    "            # puffer_loss = tf.norm(puffer_l_loss - puffer_r_loss, ord='euclidean') ** 2\n",
    "            # mouth_corner_loss = tf.norm(mouth_corner_l_loss - mouth_corner_r_loss, ord='euclidean') ** 2\n",
    "            # jaw_end_loss = tf.norm(jaw_end_l_loss - jaw_end_r_loss, ord='euclidean') ** 2\n",
    "            # ear_end_loss = tf.norm(ear_end_l_loss - ear_end_r_loss, ord='euclidean') ** 2\n",
    "\n",
    "            # diff0 = [nose_bridge_loss,r_eye_lid_loss,l_eye_lid_loss,lip_loss,r_lip_bend_loss,l_lip_bend_loss,r_lip_jaw_loss,l_lip_jaw_loss,lip_chin_loss,orbital_lower_loss,oribtal_upper_loss,puffer_loss,mouth_corner_loss,jaw_end_loss,ear_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"Test/data_0.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82357037, -0.03916234,  0.56586054],\n",
       "       [ 0.83067725, -0.01133471,  0.55663887],\n",
       "       [ 0.83082371, -0.00139268,  0.55653394],\n",
       "       ...,\n",
       "       [ 0.49656226, -0.59288941, -0.6339622 ],\n",
       "       [ 0.47684815, -0.61667432, -0.62636142],\n",
       "       [ 0.4520792 , -0.62725955, -0.63416863]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=3000, max_nn=3000)\n",
    ")\n",
    "np.array(pcd.normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([pcd], point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D DEBUG] Input Points / Samples: 5023 / 5006\n",
      "[Open3D DEBUG] #   Got kernel density: 0.020450115203857422 (s), 208.375 (MB) / 208.375 (MB) / 208 (MB)\n",
      "[Open3D DEBUG] #     Got normal field: 0.019330978393554688 (s), 215.5 (MB) / 215.5 (MB) / 215 (MB)\n",
      "[Open3D DEBUG] Point weight / Estimated Area: 4.328430e-04 / 2.174170e+00\n",
      "[Open3D DEBUG] #       Finalized tree: 0.03143811225891113 (s), 227.03125 (MB) / 227.03125 (MB) / 227 (MB)\n",
      "[Open3D DEBUG] #  Set FEM constraints: 0.04775404930114746 (s), 228.890625 (MB) / 228.890625 (MB) / 228 (MB)\n",
      "[Open3D DEBUG] #Set point constraints: 0.005423069000244141 (s), 228.90625 (MB) / 228.90625 (MB) / 228 (MB)\n",
      "[Open3D DEBUG] Leaf Nodes / Active Nodes / Ghost Nodes: 342371 / 137224 / 254057\n",
      "[Open3D DEBUG] Memory Usage: 228.906 MB\n",
      "Cycle[0] Depth[ 0/10]:\tUpdated constraints / Got system / Solved in:  0.000 /  0.000 /  0.000\t(230.094 MB)\tNodes: 8\n",
      "CG: 8.2922e-01 -> 8.2922e-01 -> 5.1265e-06 (6.2e-06) [1797602992]\n",
      "[Open3D DEBUG] # Linear system solved: 0.30851292610168457 (s), 234.3125 (MB) / 234.3125 (MB) / 234 (MB)\n",
      "[Open3D DEBUG] Got average: 0.0031671524047851562 (s), 234.859375 (MB) / 234.859375 (MB) / 234 (MB)\n",
      "[Open3D DEBUG] Iso-Value: 5.026060e-01 = 2.524590e+03 / 5.023000e+03\n",
      "[Open3D DEBUG] #          Total Solve:       1.0 (s),     254.1 (MB)\n",
      "TriangleMesh with 25599 points and 50503 triangles.\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "Cycle[0] Depth[ 1/10]:\tUpdated constraints / Got system / Solved in:  0.001 /  0.000 /  0.000\t(230.141 MB)\tNodes: 27\n",
      "  GS: 5.4343e-01 -> 5.4343e-01 -> 2.0817e-04 (3.8e-04) [8]\n",
      "Cycle[0] Depth[ 2/10]:\tUpdated constraints / Got system / Solved in:  0.001 /  0.000 /  0.000\t(230.141 MB)\tNodes: 125\n",
      "    GS: 8.3537e-01 -> 8.3537e-01 -> 2.0222e-04 (2.4e-04) [8]\n",
      "Cycle[0] Depth[ 3/10]:\tUpdated constraints / Got system / Solved in:  0.001 /  0.002 /  0.001\t(230.328 MB)\tNodes: 729\n",
      "      GS: 1.0225e+00 -> 1.0225e+00 -> 5.9498e-03 (5.8e-03) [8]\n",
      "Cycle[0] Depth[ 4/10]:\tUpdated constraints / Got system / Solved in:  0.001 /  0.004 /  0.002\t(230.578 MB)\tNodes: 4913\n",
      "        GS: 8.9089e-01 -> 8.9089e-01 -> 6.6444e-03 (7.5e-03) [8]\n",
      "Cycle[0] Depth[ 5/10]:\tUpdated constraints / Got system / Solved in:  0.001 /  0.017 /  0.062\t(233.188 MB)\tNodes: 35937\n",
      "          GS: 6.6118e-01 -> 6.6118e-01 -> 7.1414e-03 (1.1e-02) [8]\n",
      "Cycle[0] Depth[ 6/10]:\tUpdated constraints / Got system / Solved in:  0.001 /  0.006 /  0.012\t(233.500 MB)\tNodes: 14352\n",
      "            GS: 6.2936e-01 -> 6.2936e-01 -> 3.4963e-03 (5.6e-03) [8]\n",
      "Cycle[0] Depth[ 7/10]:\tUpdated constraints / Got system / Solved in:  0.001 /  0.006 /  0.019\t(234.125 MB)\tNodes: 22352\n",
      "              GS: 4.2398e-01 -> 4.2398e-01 -> 4.8663e-03 (1.1e-02) [8]\n",
      "Cycle[0] Depth[ 8/10]:\tUpdated constraints / Got system / Solved in:  0.002 /  0.014 /  0.076\t(234.266 MB)\tNodes: 25144\n",
      "                GS: 3.2280e-01 -> 3.2280e-01 -> 6.5622e-03 (2.0e-02) [8]\n",
      "Cycle[0] Depth[ 9/10]:\tUpdated constraints / Got system / Solved in:  0.002 /  0.010 /  0.013\t(234.312 MB)\tNodes: 8488\n",
      "                  GS: 2.2431e-01 -> 2.2431e-01 -> 6.4192e-03 (2.9e-02) [8]\n",
      "Cycle[0] Depth[10/10]:\tUpdated constraints / Got system / Solved in:  0.002 /  0.001 /  0.002\t(234.312 MB)\tNodes: 0\n",
      "                    GS: 0.0000e+00 -> 0.0000e+00 -> 0.0000e+00 (nan) [8]\n"
     ]
    }
   ],
   "source": [
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=10)\n",
    "print(mesh)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "head",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
